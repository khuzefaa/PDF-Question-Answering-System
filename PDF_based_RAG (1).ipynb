{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iuVBfCUSo_Sc",
        "outputId": "84892207-353d-470e-f7f8-980d66542966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”§ Installing dependencies...\n",
            "Setup complete!\n",
            "Initializing PDF Chat System...\n",
            "System ready!\n",
            " Launching PDF Q&A System...\n",
            " The interface will open in a new window\n",
            " A public link will be generated for sharing\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://ab9cac7533a996f094.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ab9cac7533a996f094.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PDF Q&A System is now running!\n",
            " Upload a PDF file and start asking questions!\n"
          ]
        }
      ],
      "source": [
        "# ðŸ“„ PDF Question Answering System - Complete in One Cell\n",
        "# Just copy, paste, and run in Google Colab!\n",
        "\n",
        "# Install dependencies\n",
        "print(\"ðŸ”§ Installing dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "install(\"langchain\")\n",
        "install(\"langchain-community\")\n",
        "install(\"chromadb\")\n",
        "install(\"sentence-transformers\")\n",
        "install(\"pypdf\")\n",
        "install(\"gradio\")\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import tempfile\n",
        "from typing import List\n",
        "import gradio as gr\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Setup complete!\")\n",
        "\n",
        "# PDF RAG System Class\n",
        "class PDFChatSystem:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing PDF Chat System...\")\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        self.vectorstore = None\n",
        "        self.chat_history = []\n",
        "        print(\"System ready!\")\n",
        "\n",
        "    def process_pdf(self, pdf_file):\n",
        "        \"\"\"Process uploaded PDF file\"\"\"\n",
        "        if pdf_file is None:\n",
        "            return \"Please upload a PDF file first!\"\n",
        "\n",
        "        try:\n",
        "            # Load PDF\n",
        "            loader = PyPDFLoader(pdf_file.name)\n",
        "            documents = loader.load()\n",
        "\n",
        "            if not documents:\n",
        "                return \" Could not extract text from PDF. Please check the file.\"\n",
        "\n",
        "            # Split into chunks\n",
        "            texts = self.text_splitter.split_documents(documents)\n",
        "\n",
        "            # Create vector store\n",
        "            self.vectorstore = Chroma.from_documents(\n",
        "                documents=texts,\n",
        "                embedding=self.embeddings\n",
        "            )\n",
        "\n",
        "            # Reset chat history for new document\n",
        "            self.chat_history = []\n",
        "\n",
        "            return f\"PDF processed successfully! \\n Extracted {len(texts)} text chunks \\n Ready for questions!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\" Error processing PDF: {str(e)}\"\n",
        "\n",
        "    def answer_question(self, question, history):\n",
        "        \"\"\"Answer question about the PDF\"\"\"\n",
        "        if not question.strip():\n",
        "            return history, \"\"\n",
        "\n",
        "        if self.vectorstore is None:\n",
        "            history.append([question, \"Please upload a PDF file first!\"])\n",
        "            return history, \"\"\n",
        "\n",
        "        try:\n",
        "            # Search for relevant chunks\n",
        "            docs = self.vectorstore.similarity_search(question, k=3)\n",
        "\n",
        "            if not docs:\n",
        "                history.append([question, \" No relevant information found in the PDF.\"])\n",
        "                return history, \"\"\n",
        "\n",
        "            # Create context from relevant chunks\n",
        "            context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "            # Generate answer using simple extraction\n",
        "            sentences = []\n",
        "            for doc in docs:\n",
        "                doc_sentences = [s.strip() + \".\" for s in doc.page_content.split('.') if len(s.strip()) > 20]\n",
        "                sentences.extend(doc_sentences)\n",
        "\n",
        "            # Score sentences based on question\n",
        "            question_words = set(word.lower() for word in question.split() if len(word) > 3)\n",
        "            scored_sentences = []\n",
        "\n",
        "            for sentence in sentences:\n",
        "                sentence_words = set(word.lower() for word in sentence.split())\n",
        "                overlap = len(question_words.intersection(sentence_words))\n",
        "                if overlap > 0:\n",
        "                    scored_sentences.append((overlap, sentence))\n",
        "\n",
        "            # Create answer\n",
        "            if scored_sentences:\n",
        "                scored_sentences.sort(reverse=True)\n",
        "                answer_sentences = [sent[1] for sent in scored_sentences[:3]]\n",
        "                answer = \" \".join(answer_sentences)\n",
        "            else:\n",
        "                answer = docs[0].page_content[:500] + \"...\"\n",
        "\n",
        "            # Add sources\n",
        "            answer += f\"\\n\\n **Sources:** Found in {len(docs)} sections of your PDF\"\n",
        "\n",
        "            history.append([question, answer])\n",
        "            return history, \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            history.append([question, f\" Error: {str(e)}\"])\n",
        "            return history, \"\"\n",
        "\n",
        "# Initialize system\n",
        "pdf_system = PDFChatSystem()\n",
        "\n",
        "# Create Gradio Interface\n",
        "def clear_chat():\n",
        "    return []\n",
        "\n",
        "# Build interface\n",
        "with gr.Blocks(title=\"PDF Q&A System\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        #  PDF Question & Answer System\n",
        "\n",
        "        **Upload any PDF and ask questions about its content!**\n",
        "\n",
        "        ### How to use:\n",
        "        1.  Upload your PDF file\n",
        "        2.  Wait for processing confirmation\n",
        "        3.  Ask questions about the content\n",
        "        4.  Get answers with source references\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            # PDF Upload Section\n",
        "            gr.Markdown(\"### ðŸ“¤ Upload PDF\")\n",
        "            pdf_input = gr.File(\n",
        "                label=\"Choose PDF File\",\n",
        "                file_types=[\".pdf\"],\n",
        "                file_count=\"single\"\n",
        "            )\n",
        "\n",
        "            process_btn = gr.Button(\"Process PDF\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            status_output = gr.Textbox(\n",
        "                label=\" Status\",\n",
        "                lines=4,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ### ðŸ’¡ Tips:\n",
        "                â€¢ Upload clear, text-based PDFs\n",
        "                â€¢ Scanned documents work but may be less accurate\n",
        "                â€¢ Processing may take a few moments for large files\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            # Chat Section\n",
        "            gr.Markdown(\"###  Ask Questions\")\n",
        "\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"Q&A Chat\",\n",
        "                height=400,\n",
        "                show_label=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                question_input = gr.Textbox(\n",
        "                    label=\"Your Question\",\n",
        "                    placeholder=\"Ask anything about your PDF content...\",\n",
        "                    lines=2,\n",
        "                    scale=4\n",
        "                )\n",
        "                ask_btn = gr.Button(\" Ask\", variant=\"primary\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\" Clear Chat\", variant=\"secondary\")\n",
        "\n",
        "            # Example questions\n",
        "            gr.Markdown(\"###  Example Questions:\")\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                â€¢ *\"What is the main topic of this document?\"*\n",
        "                â€¢ *\"Summarize the key points\"*\n",
        "                â€¢ *\"What are the conclusions?\"*\n",
        "                â€¢ *\"Explain [specific topic] mentioned in the PDF\"*\n",
        "                â€¢ *\"What does the document say about [keyword]?\"*\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "    # Event handlers (must be inside the Blocks context)\n",
        "    process_btn.click(\n",
        "        fn=pdf_system.process_pdf,\n",
        "        inputs=[pdf_input],\n",
        "        outputs=[status_output]\n",
        "    )\n",
        "\n",
        "    ask_btn.click(\n",
        "        fn=pdf_system.answer_question,\n",
        "        inputs=[question_input, chatbot],\n",
        "        outputs=[chatbot, question_input]\n",
        "    )\n",
        "\n",
        "    question_input.submit(\n",
        "        fn=pdf_system.answer_question,\n",
        "        inputs=[question_input, chatbot],\n",
        "        outputs=[chatbot, question_input]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_chat,\n",
        "        outputs=[chatbot]\n",
        "    )\n",
        "\n",
        "# Launch the app\n",
        "print(\" Launching PDF Q&A System...\")\n",
        "print(\" The interface will open in a new window\")\n",
        "print(\" A public link will be generated for sharing\")\n",
        "\n",
        "app.launch(\n",
        "    share=True,\n",
        "    debug=False,\n",
        "    show_error=True,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "print(\" PDF Q&A System is now running!\")\n",
        "print(\" Upload a PDF file and start asking questions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X2ufBnRxqbP6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWFvu-gLpAVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}