{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iuVBfCUSo_Sc",
        "outputId": "a5bae5c3-e19a-4267-8eb7-3e077bc8e366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Installing dependencies...\n",
            "‚úÖ Setup complete!\n",
            "üöÄ Initializing PDF Chat System...\n",
            "‚úÖ System ready!\n",
            "üöÄ Launching PDF Q&A System...\n",
            "üì± The interface will open in a new window\n",
            "üîó A public link will be generated for sharing\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://549bd5f85b9a4d2e91.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://549bd5f85b9a4d2e91.gradio.live\" width=\"100%\" height=\"800\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PDF Q&A System is now running!\n",
            "üìÑ Upload a PDF file and start asking questions!\n"
          ]
        }
      ],
      "source": [
        "# üìÑ PDF Question Answering System - Complete in One Cell\n",
        "# Just copy, paste, and run in Google Colab!\n",
        "\n",
        "# Install dependencies\n",
        "print(\"üîß Installing dependencies...\")\n",
        "import subprocess\n",
        "import sys\n",
        "def install(package):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
        "\n",
        "install(\"langchain\")\n",
        "install(\"langchain-community\")\n",
        "install(\"chromadb\")\n",
        "install(\"sentence-transformers\")\n",
        "install(\"pypdf\")\n",
        "install(\"gradio\")\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import tempfile\n",
        "from typing import List\n",
        "import gradio as gr\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "\n",
        "# PDF RAG System Class\n",
        "class PDFChatSystem:\n",
        "    def __init__(self):\n",
        "        print(\"üöÄ Initializing PDF Chat System...\")\n",
        "        self.embeddings = HuggingFaceEmbeddings(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        )\n",
        "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=1000,\n",
        "            chunk_overlap=200\n",
        "        )\n",
        "        self.vectorstore = None\n",
        "        self.chat_history = []\n",
        "        print(\"‚úÖ System ready!\")\n",
        "\n",
        "    def process_pdf(self, pdf_file):\n",
        "        \"\"\"Process uploaded PDF file\"\"\"\n",
        "        if pdf_file is None:\n",
        "            return \"‚ùå Please upload a PDF file first!\"\n",
        "\n",
        "        try:\n",
        "            # Load PDF\n",
        "            loader = PyPDFLoader(pdf_file.name)\n",
        "            documents = loader.load()\n",
        "\n",
        "            if not documents:\n",
        "                return \"‚ùå Could not extract text from PDF. Please check the file.\"\n",
        "\n",
        "            # Split into chunks\n",
        "            texts = self.text_splitter.split_documents(documents)\n",
        "\n",
        "            # Create vector store\n",
        "            self.vectorstore = Chroma.from_documents(\n",
        "                documents=texts,\n",
        "                embedding=self.embeddings\n",
        "            )\n",
        "\n",
        "            # Reset chat history for new document\n",
        "            self.chat_history = []\n",
        "\n",
        "            return f\"‚úÖ PDF processed successfully! \\nüìÑ Extracted {len(texts)} text chunks \\nüîç Ready for questions!\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error processing PDF: {str(e)}\"\n",
        "\n",
        "    def answer_question(self, question, history):\n",
        "        \"\"\"Answer question about the PDF\"\"\"\n",
        "        if not question.strip():\n",
        "            return history, \"\"\n",
        "\n",
        "        if self.vectorstore is None:\n",
        "            history.append([question, \"‚ùå Please upload a PDF file first!\"])\n",
        "            return history, \"\"\n",
        "\n",
        "        try:\n",
        "            # Search for relevant chunks\n",
        "            docs = self.vectorstore.similarity_search(question, k=3)\n",
        "\n",
        "            if not docs:\n",
        "                history.append([question, \"‚ùå No relevant information found in the PDF.\"])\n",
        "                return history, \"\"\n",
        "\n",
        "            # Create context from relevant chunks\n",
        "            context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "            # Generate answer using simple extraction\n",
        "            sentences = []\n",
        "            for doc in docs:\n",
        "                doc_sentences = [s.strip() + \".\" for s in doc.page_content.split('.') if len(s.strip()) > 20]\n",
        "                sentences.extend(doc_sentences)\n",
        "\n",
        "            # Score sentences based on question\n",
        "            question_words = set(word.lower() for word in question.split() if len(word) > 3)\n",
        "            scored_sentences = []\n",
        "\n",
        "            for sentence in sentences:\n",
        "                sentence_words = set(word.lower() for word in sentence.split())\n",
        "                overlap = len(question_words.intersection(sentence_words))\n",
        "                if overlap > 0:\n",
        "                    scored_sentences.append((overlap, sentence))\n",
        "\n",
        "            # Create answer\n",
        "            if scored_sentences:\n",
        "                scored_sentences.sort(reverse=True)\n",
        "                answer_sentences = [sent[1] for sent in scored_sentences[:3]]\n",
        "                answer = \" \".join(answer_sentences)\n",
        "            else:\n",
        "                answer = docs[0].page_content[:500] + \"...\"\n",
        "\n",
        "            # Add sources\n",
        "            answer += f\"\\n\\nüìö **Sources:** Found in {len(docs)} sections of your PDF\"\n",
        "\n",
        "            history.append([question, answer])\n",
        "            return history, \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            history.append([question, f\"‚ùå Error: {str(e)}\"])\n",
        "            return history, \"\"\n",
        "\n",
        "# Initialize system\n",
        "pdf_system = PDFChatSystem()\n",
        "\n",
        "# Create Gradio Interface\n",
        "def clear_chat():\n",
        "    return []\n",
        "\n",
        "# Build interface\n",
        "with gr.Blocks(title=\"PDF Q&A System\", theme=gr.themes.Soft()) as app:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üìÑ PDF Question & Answer System\n",
        "\n",
        "        **Upload any PDF and ask questions about its content!**\n",
        "\n",
        "        ### How to use:\n",
        "        1. üì§ Upload your PDF file\n",
        "        2. ‚è≥ Wait for processing confirmation\n",
        "        3. üí¨ Ask questions about the content\n",
        "        4. üîç Get answers with source references\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            # PDF Upload Section\n",
        "            gr.Markdown(\"### üì§ Upload PDF\")\n",
        "            pdf_input = gr.File(\n",
        "                label=\"Choose PDF File\",\n",
        "                file_types=[\".pdf\"],\n",
        "                file_count=\"single\"\n",
        "            )\n",
        "\n",
        "            process_btn = gr.Button(\"üîÑ Process PDF\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            status_output = gr.Textbox(\n",
        "                label=\"üìã Status\",\n",
        "                lines=4,\n",
        "                interactive=False\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ### üí° Tips:\n",
        "                ‚Ä¢ Upload clear, text-based PDFs\n",
        "                ‚Ä¢ Scanned documents work but may be less accurate\n",
        "                ‚Ä¢ Processing may take a few moments for large files\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            # Chat Section\n",
        "            gr.Markdown(\"### üí¨ Ask Questions\")\n",
        "\n",
        "            chatbot = gr.Chatbot(\n",
        "                label=\"Q&A Chat\",\n",
        "                height=400,\n",
        "                show_label=True\n",
        "            )\n",
        "\n",
        "            with gr.Row():\n",
        "                question_input = gr.Textbox(\n",
        "                    label=\"Your Question\",\n",
        "                    placeholder=\"Ask anything about your PDF content...\",\n",
        "                    lines=2,\n",
        "                    scale=4\n",
        "                )\n",
        "                ask_btn = gr.Button(\"üöÄ Ask\", variant=\"primary\", scale=1)\n",
        "\n",
        "            with gr.Row():\n",
        "                clear_btn = gr.Button(\"üßπ Clear Chat\", variant=\"secondary\")\n",
        "\n",
        "            # Example questions\n",
        "            gr.Markdown(\"### üìù Example Questions:\")\n",
        "            gr.Markdown(\n",
        "                \"\"\"\n",
        "                ‚Ä¢ *\"What is the main topic of this document?\"*\n",
        "                ‚Ä¢ *\"Summarize the key points\"*\n",
        "                ‚Ä¢ *\"What are the conclusions?\"*\n",
        "                ‚Ä¢ *\"Explain [specific topic] mentioned in the PDF\"*\n",
        "                ‚Ä¢ *\"What does the document say about [keyword]?\"*\n",
        "                \"\"\"\n",
        "            )\n",
        "\n",
        "    # Event handlers (must be inside the Blocks context)\n",
        "    process_btn.click(\n",
        "        fn=pdf_system.process_pdf,\n",
        "        inputs=[pdf_input],\n",
        "        outputs=[status_output]\n",
        "    )\n",
        "\n",
        "    ask_btn.click(\n",
        "        fn=pdf_system.answer_question,\n",
        "        inputs=[question_input, chatbot],\n",
        "        outputs=[chatbot, question_input]\n",
        "    )\n",
        "\n",
        "    question_input.submit(\n",
        "        fn=pdf_system.answer_question,\n",
        "        inputs=[question_input, chatbot],\n",
        "        outputs=[chatbot, question_input]\n",
        "    )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=clear_chat,\n",
        "        outputs=[chatbot]\n",
        "    )\n",
        "\n",
        "# Launch the app\n",
        "print(\"üöÄ Launching PDF Q&A System...\")\n",
        "print(\"üì± The interface will open in a new window\")\n",
        "print(\"üîó A public link will be generated for sharing\")\n",
        "\n",
        "app.launch(\n",
        "    share=True,\n",
        "    debug=False,\n",
        "    show_error=True,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "print(\"‚úÖ PDF Q&A System is now running!\")\n",
        "print(\"üìÑ Upload a PDF file and start asking questions!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "X2ufBnRxqbP6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AWFvu-gLpAVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}